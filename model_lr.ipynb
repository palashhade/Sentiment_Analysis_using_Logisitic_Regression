{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BkLYZJbYSSF"
      },
      "outputs": [],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LonZjWi3zS01"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0eqCr5NYwHy"
      },
      "outputs": [],
      "source": [
        "#Importing the kaggle dataset\n",
        "#Uploading the kaggle.json file\n",
        "#Setting up the kaggle api\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7_TTJ-AZcs-"
      },
      "outputs": [],
      "source": [
        "#Importing the Twitter Sentiment Dataset\n",
        "# API to fetch the dataset from kaggle.\n",
        "# !kaggle datasets download -d kazanova/sentiment140\n",
        "!kaggle datasets download -d yasserh/imdb-movie-ratings-sentiment-analysis\n",
        "#!mark is used to run shell commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swjnAIj9a4Nj"
      },
      "outputs": [],
      "source": [
        "#extracting the zip file to directory, remember that\n",
        "#csv already exists inside zip file.\n",
        "from zipfile import ZipFile\n",
        "data = '/content/imdb-movie-ratings-sentiment-analysis.zip'\n",
        "\n",
        "with ZipFile(data,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXu0pblteQj_"
      },
      "source": [
        "Importing and installing the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8UDaUolbj3m"
      },
      "outputs": [],
      "source": [
        "#Importing and installing the dependencies.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#used to create dataframes, structured table using pandas\n",
        "import re\n",
        "#Used for pattern matching re library\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "#Used for stemming the words and nltk library is for nlp.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#Used to convert textual data to numertical data Vectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#We are using logistic regression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTRnQzjedTDm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))\n",
        "#Stopwords are the words which don't have any influential meaning.\n",
        "#These words are not required for out processing.\n",
        "#Removing the stopwords as they are non-influential.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxykmeXaeOIL"
      },
      "source": [
        "Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOisNEaudep9"
      },
      "outputs": [],
      "source": [
        "#Data Processing\n",
        "#loading the data from csv file to pandas dataframe.\n",
        "t_data = pd.read_csv('/content/movie.csv', encoding ='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arqUfel6et58"
      },
      "outputs": [],
      "source": [
        "#Checking the number of rows and coloumns in t_data\n",
        "t_data.shape\n",
        "\n",
        "#printing the first five rows of the dataframe.\n",
        "t_data.head()\n",
        "t_data = t_data.rename(columns ={'ï»¿text':'text'})\n",
        "print(t_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKpsLC_ifnei"
      },
      "outputs": [],
      "source": [
        "#As it is not reading the coloumn names we are naming the coloumns.\n",
        "#as first data point is considered as coloumn name.\n",
        "#Naming the coloumn name in t_data.\n",
        "column_names =['text','id']\n",
        "t_data = pd.read_csv('/content/movie.csv', names = column_names, encoding ='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XRDBS-91V1a"
      },
      "outputs": [],
      "source": [
        "t_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybR7Z99GiPtj"
      },
      "outputs": [],
      "source": [
        "t_data.shape\n",
        "\n",
        "t_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ_iqG0KaYSL"
      },
      "outputs": [],
      "source": [
        "t_data.drop(t_data.index[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "985MkKN_iasF"
      },
      "outputs": [],
      "source": [
        "#Read the last 5 tweets as opposite to head\n",
        "t_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_punidAvi4U-"
      },
      "outputs": [],
      "source": [
        "#Dealing with missing values, by replacing or dropping\n",
        "#Checking the values and counting the number of missing values.\n",
        "t_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ILnhrqgjKQc"
      },
      "outputs": [],
      "source": [
        "#Understanding the distribution of the target variable.\n",
        "#Checking the distribution of target columns\n",
        "#Here the dataset is evenly distributed but if not we have to\n",
        "#perform upsampling or downsampling.\n",
        "t_data['id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIwzX6nijl1F"
      },
      "outputs": [],
      "source": [
        "#Convert target columns value 4 to 1\n",
        "# inplace means this change should take place in original dataset\n",
        "#Now 0 is negative tweet and 1 is positive tweet.\n",
        "# t_data.replace({'target':{4:1}}, inplace = True)\n",
        "# But I think doing this will bias the model and hence affect accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4T1rsiAl63Z"
      },
      "outputs": [],
      "source": [
        "#Stemming\n",
        "#It is the process that is done to reduce the word to its root word (keyword).\n",
        "# ex. actor, actress, acting.\n",
        "#solution: act\n",
        "#ex. choco, chocolatey, chocolates\n",
        "#solution: chocolate.\n",
        "pstem = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h4j0NGKnHDU"
      },
      "outputs": [],
      "source": [
        "def stemming(content):\n",
        "  #^ means remove everything except the given i.e., a-zA-Z\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content = [pstem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  #As mentioned earlier stopwords are the words which don't have any influential meaning .\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "\n",
        "  return stemmed_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7GGBtQUw9Qe"
      },
      "outputs": [],
      "source": [
        "#Applying the function\n",
        "t_data['stemmed_content'] = t_data['text'].apply(stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsRTa7Us9WH3"
      },
      "outputs": [],
      "source": [
        "t_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFG4UeDwUWwi"
      },
      "outputs": [],
      "source": [
        "print(t_data['stemmed_content'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_data['id'].value_counts()"
      ],
      "metadata": {
        "id": "aTA8pD-p3JPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_data = t_data.drop(t_data.index[0])"
      ],
      "metadata": {
        "id": "2EN5CtU04oT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t_data = t_data.drop(label= \"label\", axis = 0)"
      ],
      "metadata": {
        "id": "Gsc0UMjo3RTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhgRu-qTVnDy"
      },
      "outputs": [],
      "source": [
        "#seperating data and label\n",
        "X = t_data['stemmed_content'].values\n",
        "Y = t_data['id'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No6fRUjJYDQt"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Kg00LCVTQS"
      },
      "outputs": [],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QPPXdHH2FM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FBntzgSYYQ1"
      },
      "source": [
        "Splitting data into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_data['id'].value_counts()"
      ],
      "metadata": {
        "id": "7W8DNHlo16fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYt9yF5EYTol"
      },
      "outputs": [],
      "source": [
        "#Splitting data into training and testing data\n",
        "# x_train will contain all the training data tweets.\n",
        "# y_train will contain all the training data targets(LABELS).\n",
        "# x_test will contain all the testing data tweets.\n",
        "# y_test will contain all the testing data targets(LABELS).\n",
        "#If we don't set stratify then there is the chance of unfair splitting\n",
        "#regarding the random state, each time you split data, it will be split differently.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, stratify = Y, random_state = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bB-Z6iKeI50"
      },
      "outputs": [],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOzCqK-VerPr"
      },
      "outputs": [],
      "source": [
        "#Converting the text to numerical value using feature extraction.\n",
        "#Using method called Vectorizer.\n",
        "#Prioritize according to frequency.\n",
        "#Use the fit_transform method for training data alone not for test data.\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ipMZpA5gHtJ"
      },
      "outputs": [],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlIdaLhIhF6d"
      },
      "outputs": [],
      "source": [
        "print(X_test)\n",
        "\n",
        "#The first element 0 means words are in 0th tweet and so on.\n",
        "#The second element in the output means,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-XEXNxh9GY"
      },
      "source": [
        "Training the Logistic Regression Model.\n",
        "(One of the model in the ML used for binary classification and predictive analytics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPgONDXOh8NO"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter = 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsmRpUW5oOfz"
      },
      "source": [
        "Model Training phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z72EJmqAir_E"
      },
      "outputs": [],
      "source": [
        "#Model will learn and train from here\n",
        "model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJwJ6uR4oZJ7"
      },
      "source": [
        "Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iTBfxleoJwd"
      },
      "outputs": [],
      "source": [
        "#Accuracy score on the training data.\n",
        "X_train_prediction =model.predict(X_train)\n",
        "#In the above statement model will predict target on training data  given only training data without labels.\n",
        "#In the below statement we will calculate the accuracy by comparing the generated labels\n",
        "#with the actual labels.\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWqb08fNpzCh"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score on the training data: \", training_data_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWkTYn1GqBiQ"
      },
      "outputs": [],
      "source": [
        "Y_test_prediction =model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(Y_test,Y_test_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZFkfwuUrlRW"
      },
      "source": [
        "Here as the accuracy of training and test data is close, we can say that model has performed pretty well.\n",
        "\n",
        "Overfitting: Training data accuracy is much more than test data accuracy.\n",
        "ex. training data accuracy = 80% and test data accuracy = 40-50%\n",
        "\n",
        "\n",
        "Underfitting: Model performs poorly in both training and testing data, shows that the model is too simple for the data, need to design more complex model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFrzCvlVrLZw"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy Score on Test Data: {test_data_accuracy *100:.3f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-tE2Iios5-Z"
      },
      "outputs": [],
      "source": [
        "#Saving the model so that you can use it without training later.\n",
        "import pickle\n",
        "\n",
        "filename = \"modellr.sav\"\n",
        "#dumping the model, wb means write in binary format.\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTxzbEFuwn5C"
      },
      "outputs": [],
      "source": [
        "#fetching the saved file.and using the already trained model directly for prediction.\n",
        "#Using the model for new predictions.\n",
        "#Load the model.\n",
        "load_model = pickle.load(open('/content/modellr.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B7BbvATxnTM"
      },
      "outputs": [],
      "source": [
        "#This is nothing but the 200th data point\n",
        "X_new = X_test[7999]\n",
        "print(Y_test[7999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdGzG8MxyIOL"
      },
      "outputs": [],
      "source": [
        "prediction = load_model.predict(X_new)\n",
        "print(*prediction)\n",
        "\n",
        "if (prediction[0]=='0'):\n",
        "  print(\"It is a negative review\")\n",
        "else:\n",
        "  print(\"It is a positive review\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AKKB_lJyybq"
      },
      "outputs": [],
      "source": [
        "X_new = X_test[2]\n",
        "print(Y_test[2])\n",
        "prediction = load_model.predict(X_new)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print(\"It is a negative tweet\")\n",
        "else:\n",
        "  print(\"It is a positive tweet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuyMl52azPoq"
      },
      "outputs": [],
      "source": [
        "#Here our project is complete.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}